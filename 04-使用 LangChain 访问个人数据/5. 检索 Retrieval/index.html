
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="面向开发者的 LLM 入门教程，吴恩达大模型系列课程中文版">
      
      
        <meta name="author" content="Ean Yang">
      
      
        <link rel="canonical" href="https://eanyang7.github.io/prompt-engineering-for-developers/04-%E4%BD%BF%E7%94%A8%20LangChain%20%E8%AE%BF%E9%97%AE%E4%B8%AA%E4%BA%BA%E6%95%B0%E6%8D%AE/5.%20%E6%A3%80%E7%B4%A2%20Retrieval/">
      
      
        <link rel="prev" href="../4.%20%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E8%AF%8D%E5%90%91%E9%87%8F%20Vectorstores%20and%20Embeddings/">
      
      
        <link rel="next" href="../6.%20%E9%97%AE%E7%AD%94%20Question%20Answering/">
      
      
      <link rel="icon" href="../../assets/favicon.jpg">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.12">
    
    
      
        <title>第五章 检索(Retrieval) - 面向开发者的 LLM 入门教程</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.fad675c6.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.356b1318.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#retrieval" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../.." title="面向开发者的 LLM 入门教程" class="md-header__button md-logo" aria-label="面向开发者的 LLM 入门教程" data-md-component="logo">
      
  <img src="../../assets/logo.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            面向开发者的 LLM 入门教程
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              第五章 检索(Retrieval)
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple"  aria-label="切换为暗黑模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换为暗黑模式" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="deep-purple" data-md-color-accent="red"  aria-label="切换为浅色模式"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="切换为浅色模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
      </label>
    
  
</form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="分享" aria-label="分享" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/EanYang7/prompt-engineering-for-developers" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    github仓库
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="面向开发者的 LLM 入门教程" class="md-nav__button md-logo" aria-label="面向开发者的 LLM 入门教程" data-md-component="logo">
      
  <img src="../../assets/logo.jpg" alt="logo">

    </a>
    面向开发者的 LLM 入门教程
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/EanYang7/prompt-engineering-for-developers" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    github仓库
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    面向开发者的 LLM 入门课程
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../%E5%89%8D%E8%A8%80/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    前言
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    环境配置
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../01-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/1.%20%E7%AE%80%E4%BB%8B%20Introduction/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    01 面向开发者的提示工程
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../02-%E6%90%AD%E5%BB%BA%E5%9F%BA%E4%BA%8E%20ChatGPT%20%E7%9A%84%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/1.%20%E7%AE%80%E4%BB%8B%20Introduction/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    02 搭建基于 ChatGPT 的问答系统
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../03-%E4%BD%BF%E7%94%A8%20LangChain%20%E5%BC%80%E5%8F%91%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F/1.%20%E7%AE%80%E4%BB%8B%20Introduction/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    03 使用 LangChain 开发应用程序
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
    
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" checked>
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    04 使用 LangChain 访问个人数据
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            04 使用 LangChain 访问个人数据
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../1.%20%E7%AE%80%E4%BB%8B%20Introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第一章 简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../2.%20%E6%96%87%E6%A1%A3%E5%8A%A0%E8%BD%BD%20Document%20Loading/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第二章 文档加载
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../3.%20%E6%96%87%E6%A1%A3%E5%88%86%E5%89%B2%20Splitting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第三章 文档分割
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../4.%20%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E8%AF%8D%E5%90%91%E9%87%8F%20Vectorstores%20and%20Embeddings/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第四章 向量数据库与词向量(Vectorstores and Embeddings)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    第五章 检索(Retrieval)
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    第五章 检索(Retrieval)
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      一、向量数据库检索
    </span>
  </a>
  
    <nav class="md-nav" aria-label="一、向量数据库检索">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-similarity-search" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 相似性检索（Similarity Search）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-mmr" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 解决多样性：最大边际相关性(MMR)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 解决特殊性：使用元数据
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#14-llm" class="md-nav__link">
    <span class="md-ellipsis">
      1.4 解决特殊性：在元数据中使用自查询检索器（LLM辅助检索）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#15" class="md-nav__link">
    <span class="md-ellipsis">
      1.5 其他技巧：压缩
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      二、结合各种技术
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      三、其他类型的检索
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      四、总结
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      五、英文版
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../6.%20%E9%97%AE%E7%AD%94%20Question%20Answering/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第六章 问答
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../7.%20%E8%81%8A%E5%A4%A9%20Chat/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第七章、聊天 Chat
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../8.%20%E6%80%BB%E7%BB%93%20Summary/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第八章、总结
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../readme/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第四部分 使用 LangChain 访问个人数据
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      一、向量数据库检索
    </span>
  </a>
  
    <nav class="md-nav" aria-label="一、向量数据库检索">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-similarity-search" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 相似性检索（Similarity Search）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-mmr" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 解决多样性：最大边际相关性(MMR)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 解决特殊性：使用元数据
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#14-llm" class="md-nav__link">
    <span class="md-ellipsis">
      1.4 解决特殊性：在元数据中使用自查询检索器（LLM辅助检索）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#15" class="md-nav__link">
    <span class="md-ellipsis">
      1.5 其他技巧：压缩
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      二、结合各种技术
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      三、其他类型的检索
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      四、总结
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      五、英文版
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/EanYang7/prompt-engineering-for-developers/tree/main/docs/04-使用 LangChain 访问个人数据/5. 检索 Retrieval.md" title="编辑此页" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/EanYang7/prompt-engineering-for-developers/tree/main/docs/04-使用 LangChain 访问个人数据/5. 检索 Retrieval.md" title="查看本页的源代码" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5Z"/></svg>
    </a>
  


<h1 id="retrieval">第五章 检索(Retrieval)<a class="headerlink" href="#retrieval" title="Permanent link">⚓︎</a></h1>
<p>在构建检索增强生成 (RAG) 系统时，信息检索是核心环节。检索模块负责对用户查询进行分析，从知识库中快速定位相关文档或段落，为后续的语言生成提供信息支持。<strong>检索是指根据用户的问题去向量数据库中搜索与问题相关的文档内容</strong>，当我们访问和查询向量数据库时可能会运用到如下几种技术：</p>
<ul>
<li>基本语义相似度(Basic semantic similarity)</li>
<li>最大边际相关性(Maximum marginal relevance，MMR)</li>
<li>过滤元数据</li>
<li>LLM辅助检索</li>
</ul>
<p><img alt="" src="../../figures/C4/Retrieval.png" /></p>
<div align='center'> 图 4.5.1 检索技术 </div>

<p>使用基本的相似性搜索大概能解决你80%的相关检索工作，但对于那些相似性搜索失败的边缘情况该如何解决呢？这一章节我们将介绍几种检索方法，以及解决检索边缘情况的技巧，让我们一起开始学习吧！</p>
<h2 id="_1">一、向量数据库检索<a class="headerlink" href="#_1" title="Permanent link">⚓︎</a></h2>
<p>本章节需要使用<code>lark</code>包，若环境中未安装过此包，请运行以下命令安装：</p>
<div class="highlight"><pre><span></span><code><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">Uq</span> <span class="n">lark</span>
</code></pre></div>
<h3 id="11-similarity-search">1.1 相似性检索（Similarity Search）<a class="headerlink" href="#11-similarity-search" title="Permanent link">⚓︎</a></h3>
<p>以我们的流程为例，前面课程已经存储了向量数据库(<code>VectorDB</code>)，包含各文档的语义向量表示。首先将上节课所保存的向量数据库(<code>VectorDB</code>)加载进来：</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">langchain.vectorstores</span> <span class="kn">import</span> <span class="n">Chroma</span>
<span class="kn">from</span> <span class="nn">langchain.embeddings.openai</span> <span class="kn">import</span> <span class="n">OpenAIEmbeddings</span>

<span class="n">persist_directory_chinese</span> <span class="o">=</span> <span class="s1">&#39;docs/chroma/matplotlib/&#39;</span>

<span class="n">embedding</span> <span class="o">=</span> <span class="n">OpenAIEmbeddings</span><span class="p">()</span>

<span class="n">vectordb_chinese</span> <span class="o">=</span> <span class="n">Chroma</span><span class="p">(</span>
    <span class="n">persist_directory</span><span class="o">=</span><span class="n">persist_directory_chinese</span><span class="p">,</span>
    <span class="n">embedding_function</span><span class="o">=</span><span class="n">embedding</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">vectordb_chinese</span><span class="o">.</span><span class="n">_collection</span><span class="o">.</span><span class="n">count</span><span class="p">())</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>27
</code></pre></div>
<p>下面我们来实现一下语义的相似度搜索，我们把三句话存入向量数据库Chroma中，然后我们提出问题让向量数据库根据问题来搜索相关答案：</p>
<div class="highlight"><pre><span></span><code><span class="n">texts_chinese</span> <span class="o">=</span> <span class="p">[</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;毒鹅膏菌（Amanita phalloides）具有大型且引人注目的地上（epigeous）子实体（basidiocarp）&quot;&quot;&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;一种具有大型子实体的蘑菇是毒鹅膏菌（Amanita phalloides）。某些品种全白。&quot;&quot;&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A. phalloides，又名死亡帽，是已知所有蘑菇中最有毒的一种。&quot;&quot;&quot;</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div>
<p>我们可以看到前两句都是描述的是一种叫“鹅膏菌”的菌类，包括它们的特征：有较大的子实体，第三句描述的是“鬼笔甲”，一种已知的最毒的蘑菇，它的特征就是：含有剧毒。对于这个例子，我们将创建一个小数据库，我们可以作为一个示例来使用。</p>
<div class="highlight"><pre><span></span><code><span class="n">smalldb_chinese</span> <span class="o">=</span> <span class="n">Chroma</span><span class="o">.</span><span class="n">from_texts</span><span class="p">(</span><span class="n">texts_chinese</span><span class="p">,</span> <span class="n">embedding</span><span class="o">=</span><span class="n">embedding</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>100%|██████████| 1/1 [00:00&lt;00:00,  1.51it/s]
</code></pre></div>
<p>下面是我们对于这个示例所提出的问题：</p>
<div class="highlight"><pre><span></span><code><span class="n">question_chinese</span> <span class="o">=</span> <span class="s2">&quot;告诉我关于具有大型子实体的全白色蘑菇的信息&quot;</span>
</code></pre></div>
<p>现在，让针对上面问题进行<strong>相似性搜索</strong>，设置 k=2 ，只返回两个最相关的文档。</p>
<div class="highlight"><pre><span></span><code><span class="n">smalldb_chinese</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">question_chinese</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>[Document(page_content=&#39;一种具有大型子实体的蘑菇是毒鹅膏菌（Amanita phalloides）。某些品种全白。&#39;, metadata={}),
 Document(page_content=&#39;毒鹅膏菌（Amanita phalloides）具有大型且引人注目的地上（epigeous）子实体（basidiocarp）&#39;, metadata={})]
</code></pre></div>
<p>我们现在可以看到，向量数据库返回了 2 个文档，就是我们存入向量数据库中的第一句和第二句。这里我们很明显的就可以看到 chroma 的 similarity_search（相似性搜索） 方法可以根据问题的语义去数据库中搜索与之相关性最高的文档，也就是搜索到了第一句和第二句的文本。但这似乎还存在一些问题，因为第一句和第二句的含义非常接近，他们都是描述“鹅膏菌”及其“子实体”的，所以假如只返回其中的一句就足以满足要求了，如果返回两句含义非常接近的文本感觉是一种资源的浪费。下面我们来看一下 max_marginal_relevance_search 的搜索结果。</p>
<h3 id="12-mmr">1.2 解决多样性：最大边际相关性(MMR)<a class="headerlink" href="#12-mmr" title="Permanent link">⚓︎</a></h3>
<p>最大边际相关模型 (MMR，Maximal Marginal Relevance) 是实现多样性检索的常用算法。</p>
<p><img alt="" src="../../figures/C4/MMR_algorithm.png" /></p>
<div align='center'> 图 4.5.2 MMR </div>

<p><strong>MMR 的基本思想是同时考量查询与文档的相关度，以及文档之间的相似度</strong>。相关度确保返回结果对查询高度相关，相似度则鼓励不同语义的文档被包含进结果集。具体来说，它计算每个候选文档与查询的相关度，并减去与已经选入结果集的文档的相似度。这样更不相似的文档会有更高的得分。</p>
<p>总之，MMR 是解决检索冗余问题、提供多样性结果的一种简单高效的算法。它平衡了相关性和多样性，适用于对多样信息需求较强的应用场景。</p>
<p>我们来看一个利用 MMR 从蘑菇知识库中检索信息的示例。首先加载有关蘑菇的文档，然后运行 MMR 算法，设置 fetch_k 参数，用来告诉向量数据库我们最终需要 k 个结果返回。fetch_k=3 ，也就是我们最初获取 3 个文档，k=2 表示返回最不同的 2 个文档。</p>
<div class="highlight"><pre><span></span><code><span class="n">smalldb_chinese</span><span class="o">.</span><span class="n">max_marginal_relevance_search</span><span class="p">(</span><span class="n">question_chinese</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">fetch_k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>[Document(page_content=&#39;一种具有大型子实体的蘑菇是毒鹅膏菌（Amanita phalloides）。某些品种全白。&#39;, metadata={}),
 Document(page_content=&#39;A. phalloides，又名死亡帽，是已知所有蘑菇中最有毒的一种。&#39;, metadata={})]
</code></pre></div>
<p>这里我们看到 max_marginal_relevance_search（最大边际相关搜索） 返回了第二和第三句的文本，尽管第三句与我们的问题的相关性不太高，但是这样的结果其实应该是更加的合理，因为第一句和第二句文本本来就有着相似的含义，所以只需要返回其中的一句就可以了，另外再返回一个与问题相关性弱一点的答案(第三句文本)，这样似乎增强了答案的多样性，相信用户也会更加偏爱</p>
<p>还记得在上一节中我们介绍了两种向量数据在查询时的失败场景吗？当向量数据库中存在相同的文档时，而用户的问题又与这些重复的文档高度相关时，向量数据库会出现返回重复文档的情况。现在我们就可以运用Langchain的   max_marginal_relevance_search 来解决这个问题：</p>
<p>我们首先看看前两个文档，只看前几个字符，可以看到它们是相同的。</p>
<div class="highlight"><pre><span></span><code><span class="n">question_chinese</span> <span class="o">=</span> <span class="s2">&quot;Matplotlib是什么？&quot;</span>
<span class="n">docs_ss_chinese</span> <span class="o">=</span> <span class="n">vectordb_chinese</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">question_chinese</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;docs[0]: &quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">docs_ss_chinese</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;docs[1]: &quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">docs_ss_chinese</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>docs[0]: 
第⼀回：Matplotlib 初相识
⼀、认识matplotlib
Matplotlib 是⼀个 Python 2D 绘图库，能够以多种硬拷⻉格式和跨平台的交互式环境⽣成出版物质量的图形，⽤来绘制各种

docs[1]: 
第⼀回：Matplotlib 初相识
⼀、认识matplotlib
Matplotlib 是⼀个 Python 2D 绘图库，能够以多种硬拷⻉格式和跨平台的交互式环境⽣成出版物质量的图形，⽤来绘制各种
</code></pre></div>
<p>这里如果我们使用相似查询，会得到两个重复的结果，读者可以自己尝试一下，这里不再展示。我们可以使用 <code>MMR</code> 得到不一样的结果。</p>
<div class="highlight"><pre><span></span><code><span class="n">docs_mmr_chinese</span> <span class="o">=</span> <span class="n">vectordb_chinese</span><span class="o">.</span><span class="n">max_marginal_relevance_search</span><span class="p">(</span><span class="n">question_chinese</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div>
<p>当我们运行 MMR 后得到结果时，我们可以看到第一个与之前的相同，因为那是最相似的。</p>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">docs_mmr_chinese</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>第⼀回：Matplotlib 初相识
⼀、认识matplotlib
Matplotlib 是⼀个 Python 2D 绘图库，能够以多种硬拷⻉格式和跨平台的交互式环境⽣成出版物质量的图形，⽤来绘制各种
</code></pre></div>
<p>但是当我们进行到第二个时，我们可以看到它是不同的。</p>
<p>它在回应中获得了一些多样性。</p>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">docs_mmr_chinese</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>By Datawhale 数据可视化开源⼩组
© Copyright © Copyright 2021.y轴分为左右两个，因此 tick1 对应左侧的轴； tick2 对应右侧的轴。
x轴分为上下两个
</code></pre></div>
<p>从以上结果中可以看到，向量数据库返回了 2 篇完全不同的文档，这是因为我们使用的是 MMR 搜索，它把搜索结果中相似度很高的文档做了过滤，所以它保留了结果的相关性又同时兼顾了结果的多样性。</p>
<h3 id="13">1.3 解决特殊性：使用元数据<a class="headerlink" href="#13" title="Permanent link">⚓︎</a></h3>
<p>在上一节课中，关于失败的应用场景我们还提出了一个问题，是询问了关于文档中某一讲的问题，但得到的结果中也包括了来自其他讲的结果。这是我们所不希望看到的结果，之所以产生这样的结果是因为当我们向向量数据库提出问题时，数据库并没有很好的理解问题的语义，所以返回的结果不如预期。要解决这个问题，我们可以通过过滤元数据的方式来实现精准搜索，当前很多向量数据库都支持对<code>元数据（metadata）</code>的操作：</p>
<p><code>metadata</code>为每个嵌入的块(embedded chunk)提供上下文。</p>
<div class="highlight"><pre><span></span><code><span class="n">question_chinese</span> <span class="o">=</span> <span class="s2">&quot;他们在第二讲中对Figure说了些什么？&quot;</span>  
</code></pre></div>
<p>现在，我们以手动的方式来解决这个问题，我们会指定一个元数据过滤器<code>filter</code></p>
<div class="highlight"><pre><span></span><code><span class="n">docs_chinese</span> <span class="o">=</span> <span class="n">vectordb_chinese</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span>
    <span class="n">question_chinese</span><span class="p">,</span>
    <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="nb">filter</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;source&quot;</span><span class="p">:</span><span class="s2">&quot;docs/matplotlib/第二回：艺术画笔见乾坤.pdf&quot;</span><span class="p">}</span>
<span class="p">)</span>
</code></pre></div>
<p>接下来，我们可以看到结果都来自对应的章节</p>
<div class="highlight"><pre><span></span><code><span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">docs_chinese</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">metadata</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>{&#39;source&#39;: &#39;docs/matplotlib/第二回：艺术画笔见乾坤.pdf&#39;, &#39;page&#39;: 9}
{&#39;source&#39;: &#39;docs/matplotlib/第二回：艺术画笔见乾坤.pdf&#39;, &#39;page&#39;: 10}
{&#39;source&#39;: &#39;docs/matplotlib/第二回：艺术画笔见乾坤.pdf&#39;, &#39;page&#39;: 0}
</code></pre></div>
<p>当然，我们不能每次都采用手动的方式来解决这个问题，这会显得不够智能。下一小节中，我们将展示通过LLM来解决这个问题。</p>
<h3 id="14-llm">1.4 解决特殊性：在元数据中使用自查询检索器（LLM辅助检索）<a class="headerlink" href="#14-llm" title="Permanent link">⚓︎</a></h3>
<p>在上例中，我们手动设置了过滤参数 filter 来过滤指定文档。但这种方式不够智能，需要人工指定过滤条件。如何自动从用户问题中提取过滤信息呢？</p>
<p>LangChain提供了SelfQueryRetriever模块，它可以通过语言模型从问题语句中分析出:</p>
<p>1) 向量搜索的查询字符串(search term)</p>
<p>2) 过滤文档的元数据条件(Filter)</p>
<p>以“除了维基百科,还有哪些健康网站”为例,SelfQueryRetriever可以推断出“除了维基百科”表示需要过滤的条件,即排除维基百科的文档。</p>
<p>它使用语言模型自动解析语句语义,提取过滤信息,无需手动设置。这种基于理解的元数据过滤更加智能方便,可以自动处理更复杂的过滤逻辑。</p>
<p>掌握利用语言模型实现自动化过滤的技巧,可以大幅降低构建针对性问答系统的难度。这种自抽取查询的方法使检索更加智能和动态。</p>
<p>其原理如下图所示：</p>
<p><img alt="" src="../../figures/C4/LLM%20Aided%20Retrieval.png" /></p>
<div align='center'> 图 4.5.3 自抽取查询 </div>

<p>下面我们就来实现一下LLM辅助检索：</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>
<span class="kn">from</span> <span class="nn">langchain.retrievers.self_query.base</span> <span class="kn">import</span> <span class="n">SelfQueryRetriever</span>
<span class="kn">from</span> <span class="nn">langchain.chains.query_constructor.base</span> <span class="kn">import</span> <span class="n">AttributeInfo</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>
<p>这里我们首先定义了 metadata_field_info_chinese ，它包含了元数据的过滤条件 <code>source</code> 和 <code>page</code> , 其中 source 的作用是告诉 LLM 我们想要的数据来自于哪里， page 告诉 LLM 我们需要提取相关的内容在原始文档的哪一页。有了 metadata_field_info_chinese 信息后，LLM会自动从用户的问题中提取出上图中的 Filter 和 Search term 两项，然后向量数据库基于这两项去搜索相关的内容。下面我们看一下查询结果：</p>
<div class="highlight"><pre><span></span><code><span class="n">metadata_field_info_chinese</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">AttributeInfo</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;source&quot;</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The lecture the chunk is from, should be one of `docs/matplotlib/第一回：Matplotlib初相识.pdf`, `docs/matplotlib/第二回：艺术画笔见乾坤.pdf`, or `docs/matplotlib/第三回：布局格式定方圆.pdf`&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;string&quot;</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">AttributeInfo</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;page&quot;</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The page from the lecture&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;integer&quot;</span><span class="p">,</span>
    <span class="p">),</span>
<span class="p">]</span>

<span class="n">document_content_description_chinese</span> <span class="o">=</span> <span class="s2">&quot;Matplotlib 课堂讲义&quot;</span>
<span class="n">retriever_chinese</span> <span class="o">=</span> <span class="n">SelfQueryRetriever</span><span class="o">.</span><span class="n">from_llm</span><span class="p">(</span>
    <span class="n">llm</span><span class="p">,</span>
    <span class="n">vectordb_chinese</span><span class="p">,</span>
    <span class="n">document_content_description_chinese</span><span class="p">,</span>
    <span class="n">metadata_field_info_chinese</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="n">question_chinese</span> <span class="o">=</span> <span class="s2">&quot;他们在第二讲中对Figure做了些什么？&quot;</span>  
</code></pre></div>
<p>当你第一次执行下一行时，你会收到关于predict_and_parse已被弃用的<strong>警告</strong>。 这可以安全地忽略。</p>
<div class="highlight"><pre><span></span><code><span class="n">docs_chinese</span> <span class="o">=</span> <span class="n">retriever_chinese</span><span class="o">.</span><span class="n">get_relevant_documents</span><span class="p">(</span><span class="n">question_chinese</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>/root/autodl-tmp/env/gpt/lib/python3.10/site-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.
  warnings.warn(


query=&#39;Figure&#39; filter=Comparison(comparator=&lt;Comparator.EQ: &#39;eq&#39;&gt;, attribute=&#39;source&#39;, value=&#39;docs/matplotlib/第二回：艺术画笔见乾坤.pdf&#39;) limit=None
</code></pre></div>
<p>打印可以看到查询结果，基于子查询检索器，我们检索到的结果都是在第二回的文档中：</p>
<div class="highlight"><pre><span></span><code><span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">docs_chinese</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">metadata</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>{&#39;source&#39;: &#39;docs/matplotlib/第二回：艺术画笔见乾坤.pdf&#39;, &#39;page&#39;: 9}
{&#39;source&#39;: &#39;docs/matplotlib/第二回：艺术画笔见乾坤.pdf&#39;, &#39;page&#39;: 10}
{&#39;source&#39;: &#39;docs/matplotlib/第二回：艺术画笔见乾坤.pdf&#39;, &#39;page&#39;: 0}
{&#39;source&#39;: &#39;docs/matplotlib/第二回：艺术画笔见乾坤.pdf&#39;, &#39;page&#39;: 6}
</code></pre></div>
<h3 id="15">1.5 其他技巧：压缩<a class="headerlink" href="#15" title="Permanent link">⚓︎</a></h3>
<p>在使用向量检索获取相关文档时，直接返回整个文档片段可能带来资源浪费，因为实际相关的只是文档的一小部分。为改进这一点，LangChain提供了一种“<code>压缩</code>”检索机制。其工作原理是，<strong>先使用标准向量检索获得候选文档，然后基于查询语句的语义，使用语言模型压缩这些文档,只保留与问题相关的部分</strong>。例如，对“蘑菇的营养价值”这个查询，检索可能返回整篇有关蘑菇的长文档。经压缩后，只提取文档中与“营养价值”相关的句子。</p>
<p><img alt="" src="../../figures/C4/Compression.png" /></p>
<div align='center'> 图 4.5.4 压缩 </div>

<p>从上图中我们看到，当向量数据库返回了所有与问题相关的所有文档块的全部内容后，会有一个Compression LLM来负责对这些返回的文档块的内容进行压缩，所谓压缩是指仅从文档块中提取出和用户问题相关的内容，并舍弃掉那些不相关的内容。</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">langchain.retrievers</span> <span class="kn">import</span> <span class="n">ContextualCompressionRetriever</span>
<span class="kn">from</span> <span class="nn">langchain.retrievers.document_compressors</span> <span class="kn">import</span> <span class="n">LLMChainExtractor</span>

<span class="k">def</span> <span class="nf">pretty_print_docs</span><span class="p">(</span><span class="n">docs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;-&#39;</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;Document </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">:</span><span class="se">\n\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">d</span><span class="o">.</span><span class="n">page_content</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">docs</span><span class="p">)]))</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">compressor</span> <span class="o">=</span> <span class="n">LLMChainExtractor</span><span class="o">.</span><span class="n">from_llm</span><span class="p">(</span><span class="n">llm</span><span class="p">)</span>  <span class="c1"># 压缩器</span>

<span class="n">compression_retriever_chinese</span> <span class="o">=</span> <span class="n">ContextualCompressionRetriever</span><span class="p">(</span>
    <span class="n">base_compressor</span><span class="o">=</span><span class="n">compressor</span><span class="p">,</span>
    <span class="n">base_retriever</span><span class="o">=</span><span class="n">vectordb_chinese</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">()</span>
<span class="p">)</span>
<span class="c1"># 对源文档进行压缩</span>

<span class="n">question_chinese</span> <span class="o">=</span> <span class="s2">&quot;Matplotlib是什么？&quot;</span>
<span class="n">compressed_docs_chinese</span> <span class="o">=</span> <span class="n">compression_retriever_chinese</span><span class="o">.</span><span class="n">get_relevant_documents</span><span class="p">(</span><span class="n">question_chinese</span><span class="p">)</span>
<span class="n">pretty_print_docs</span><span class="p">(</span><span class="n">compressed_docs_chinese</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Document 1:

Matplotlib 是⼀个 Python 2D 绘图库，能够以多种硬拷⻉格式和跨平台的交互式环境⽣成出版物质量的图形，⽤来绘制各种静态，动态，交互式的图表。
----------------------------------------------------------------------------------------------------
Document 2:

Matplotlib 是⼀个 Python 2D 绘图库，能够以多种硬拷⻉格式和跨平台的交互式环境⽣成出版物质量的图形，⽤来绘制各种静态，动态，交互式的图表。
</code></pre></div>
<p>在上面的代码中我们定义了一个 LLMChainExtractor ，它是一个压缩器，它负责从向量数据库返回的文档块中提取相关信息，然后我们还定义了 ContextualCompressionRetriever ，它有两个参数：base_compressor 和 base_retriever，其中 base_compressor 是我们前面定义的 LLMChainExtractor 的实例，base_retriever是早前定义的 vectordb 产生的检索器。</p>
<p>现在当我们提出问题后，查看结果文档，我们可以看到两件事。</p>
<ol>
<li>它们比正常文档短很多</li>
<li>仍然有一些重复的东西，这是因为在底层我们使用的是语义搜索算法。</li>
</ol>
<p>从上述例子中，我们可以发现这种压缩可以有效提升输出质量，同时节省通过长文档带来的计算资源浪费，降低成本。上下文相关的压缩检索技术，使得到的支持文档更严格匹配问题需求，是提升问答系统效率的重要手段。读者可以在实际应用中考虑这一技术。</p>
<h2 id="_2">二、结合各种技术<a class="headerlink" href="#_2" title="Permanent link">⚓︎</a></h2>
<p>为了去掉结果中的重复文档，我们在从向量数据库创建检索器时，可以将搜索类型设置为 MMR 。然后我们可以重新运行这个过程，可以看到我们返回的是一个过滤过的结果集，其中不包含任何重复的信息。</p>
<div class="highlight"><pre><span></span><code><span class="n">compression_retriever_chinese</span> <span class="o">=</span> <span class="n">ContextualCompressionRetriever</span><span class="p">(</span>
    <span class="n">base_compressor</span><span class="o">=</span><span class="n">compressor</span><span class="p">,</span>
    <span class="n">base_retriever</span><span class="o">=</span><span class="n">vectordb_chinese</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">(</span><span class="n">search_type</span> <span class="o">=</span> <span class="s2">&quot;mmr&quot;</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">question_chinese</span> <span class="o">=</span> <span class="s2">&quot;Matplotlib是什么？&quot;</span>
<span class="n">compressed_docs_chinese</span> <span class="o">=</span> <span class="n">compression_retriever_chinese</span><span class="o">.</span><span class="n">get_relevant_documents</span><span class="p">(</span><span class="n">question_chinese</span><span class="p">)</span>
<span class="n">pretty_print_docs</span><span class="p">(</span><span class="n">compressed_docs_chinese</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Document 1:

Matplotlib 是⼀个 Python 2D 绘图库，能够以多种硬拷⻉格式和跨平台的交互式环境⽣成出版物质量的图形，⽤来绘制各种静态，动态，交互式的图表。
</code></pre></div>
<h2 id="_3">三、其他类型的检索<a class="headerlink" href="#_3" title="Permanent link">⚓︎</a></h2>
<p>值得注意的是，vetordb 并不是唯一一种检索文档的工具。<code>LangChain</code> 还提供了其他检索文档的方式，例如：<code>TF-IDF</code> 或 <code>SVM</code>。</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">langchain.retrievers</span> <span class="kn">import</span> <span class="n">SVMRetriever</span>
<span class="kn">from</span> <span class="nn">langchain.retrievers</span> <span class="kn">import</span> <span class="n">TFIDFRetriever</span>
<span class="kn">from</span> <span class="nn">langchain.document_loaders</span> <span class="kn">import</span> <span class="n">PyPDFLoader</span>
<span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>

<span class="c1"># 加载PDF</span>
<span class="n">loader_chinese</span> <span class="o">=</span> <span class="n">PyPDFLoader</span><span class="p">(</span><span class="s2">&quot;docs/matplotlib/第一回：Matplotlib初相识.pdf&quot;</span><span class="p">)</span>
<span class="n">pages_chinese</span> <span class="o">=</span> <span class="n">loader_chinese</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="n">all_page_text_chinese</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">page_content</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pages_chinese</span><span class="p">]</span>
<span class="n">joined_page_text_chinese</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">all_page_text_chinese</span><span class="p">)</span>

<span class="c1"># 分割文本</span>
<span class="n">text_splitter_chinese</span> <span class="o">=</span> <span class="n">RecursiveCharacterTextSplitter</span><span class="p">(</span><span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">1500</span><span class="p">,</span><span class="n">chunk_overlap</span> <span class="o">=</span> <span class="mi">150</span><span class="p">)</span>
<span class="n">splits_chinese</span> <span class="o">=</span> <span class="n">text_splitter_chinese</span><span class="o">.</span><span class="n">split_text</span><span class="p">(</span><span class="n">joined_page_text_chinese</span><span class="p">)</span>

<span class="c1"># 检索</span>
<span class="n">svm_retriever</span> <span class="o">=</span> <span class="n">SVMRetriever</span><span class="o">.</span><span class="n">from_texts</span><span class="p">(</span><span class="n">splits_chinese</span><span class="p">,</span> <span class="n">embedding</span><span class="p">)</span>
<span class="n">tfidf_retriever</span> <span class="o">=</span> <span class="n">TFIDFRetriever</span><span class="o">.</span><span class="n">from_texts</span><span class="p">(</span><span class="n">splits_chinese</span><span class="p">)</span>
</code></pre></div>
<p>这里我们定义了 SVMRetriever ，和 TFIDFRetriever 两个检索器，接下来我们分别测试 TF-IDF 检索以及 SVM 检索的效果：</p>
<div class="highlight"><pre><span></span><code><span class="n">question_chinese</span> <span class="o">=</span> <span class="s2">&quot;这门课的主要主题是什么？&quot;</span> 
<span class="n">docs_svm_chinese</span> <span class="o">=</span> <span class="n">svm_retriever</span><span class="o">.</span><span class="n">get_relevant_documents</span><span class="p">(</span><span class="n">question_chinese</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">docs_svm_chinese</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>page_content=&#39;fig, ax = plt.subplots()  \n# step4 绘制图像，  这⼀模块的扩展参考第⼆章进⼀步学习\nax.plot(x, y, label=\&#39;linear\&#39;)  \n# step5 添加标签，⽂字和图例，这⼀模块的扩展参考第四章进⼀步学习\nax.set_xlabel(\&#39;x label\&#39;) \nax.set_ylabel(\&#39;y label\&#39;) \nax.set_title(&quot;Simple Plot&quot;)  \nax.legend() ;\n思考题\n请思考两种绘图模式的优缺点和各⾃适合的使⽤场景\n在第五节绘图模板中我们是以 OO 模式作为例⼦展示的，请思考并写⼀个 pyplot 绘图模式的简单模板&#39; metadata={}
</code></pre></div>
<p>可以看出，SVM 检索的效果要差于 VectorDB。</p>
<div class="highlight"><pre><span></span><code><span class="n">question_chinese</span> <span class="o">=</span> <span class="s2">&quot;Matplotlib是什么？&quot;</span>
<span class="n">docs_tfidf_chinese</span> <span class="o">=</span> <span class="n">tfidf_retriever</span><span class="o">.</span><span class="n">get_relevant_documents</span><span class="p">(</span><span class="n">question_chinese</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">docs_tfidf_chinese</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>page_content=&#39;fig, ax = plt.subplots()  \n# step4 绘制图像，  这⼀模块的扩展参考第⼆章进⼀步学习\nax.plot(x, y, label=\&#39;linear\&#39;)  \n# step5 添加标签，⽂字和图例，这⼀模块的扩展参考第四章进⼀步学习\nax.set_xlabel(\&#39;x label\&#39;) \nax.set_ylabel(\&#39;y label\&#39;) \nax.set_title(&quot;Simple Plot&quot;)  \nax.legend() ;\n思考题\n请思考两种绘图模式的优缺点和各⾃适合的使⽤场景\n在第五节绘图模板中我们是以 OO 模式作为例⼦展示的，请思考并写⼀个 pyplot 绘图模式的简单模板&#39; metadata={}
</code></pre></div>
<p>同样，TF-IDF 检索的效果也不尽如人意。</p>
<h2 id="_4">四、总结<a class="headerlink" href="#_4" title="Permanent link">⚓︎</a></h2>
<p>今天的课程涵盖了向量检索的多项新技术，让我们快速回顾关键要点：</p>
<p>1) MMR 算法可以实现兼具相关性与多样性的检索结果，避免信息冗余。</p>
<p>2) 定义元数据字段可以进行针对性过滤，提升匹配准确率。</p>
<p>3) SelfQueryRetriever 模块通过语言模型自动分析语句，提取查询字符串与过滤条件，无需手动设置，使检索更智能。</p>
<p>4) ContextualCompressionRetriever 实现压缩检索，仅返回与问题相关的文档片段，可以大幅提升效率并节省计算资源。</p>
<p>5) 除向量检索外，还简要介绍了基于 SVM 和 TF-IDF 的检索方法。</p>
<p>这些技术为我们构建可交互的语义搜索模块提供了重要支持。熟练掌握各检索算法的适用场景，将大大增强问答系统的智能水平。希望本节的教程能够对大家有所帮助!</p>
<h2 id="_5">五、英文版<a class="headerlink" href="#_5" title="Permanent link">⚓︎</a></h2>
<p><strong>1.1 相似性检索</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">langchain.vectorstores</span> <span class="kn">import</span> <span class="n">Chroma</span>
<span class="kn">from</span> <span class="nn">langchain.embeddings.openai</span> <span class="kn">import</span> <span class="n">OpenAIEmbeddings</span>

<span class="n">persist_directory</span> <span class="o">=</span> <span class="s1">&#39;docs/chroma/cs229_lectures/&#39;</span>

<span class="n">embedding</span> <span class="o">=</span> <span class="n">OpenAIEmbeddings</span><span class="p">()</span>
<span class="n">vectordb</span> <span class="o">=</span> <span class="n">Chroma</span><span class="p">(</span>
    <span class="n">persist_directory</span><span class="o">=</span><span class="n">persist_directory</span><span class="p">,</span>
    <span class="n">embedding_function</span><span class="o">=</span><span class="n">embedding</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vectordb</span><span class="o">.</span><span class="n">_collection</span><span class="o">.</span><span class="n">count</span><span class="p">())</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>209
</code></pre></div>
<p>简单示例</p>
<div class="highlight"><pre><span></span><code><span class="n">texts</span> <span class="o">=</span> <span class="p">[</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).&quot;&quot;&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.&quot;&quot;&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.&quot;&quot;&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">smalldb</span> <span class="o">=</span> <span class="n">Chroma</span><span class="o">.</span><span class="n">from_texts</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">embedding</span><span class="o">=</span><span class="n">embedding</span><span class="p">)</span>

<span class="n">question</span> <span class="o">=</span> <span class="s2">&quot;Tell me about all-white mushrooms with large fruiting bodies&quot;</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;相似性检索：&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">smalldb</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MMR 检索：&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">smalldb_chinese</span><span class="o">.</span><span class="n">max_marginal_relevance_search</span><span class="p">(</span><span class="n">question</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">fetch_k</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>  0%|          | 0/1 [00:00&lt;?, ?it/s]100%|██████████| 1/1 [00:00&lt;00:00,  2.55it/s]


相似性检索：
[Document(page_content=&#39;A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.&#39;, metadata={}), Document(page_content=&#39;The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).&#39;, metadata={})]
MMR 检索：
[Document(page_content=&#39;一种具有大型子实体的蘑菇是毒鹅膏菌（Amanita phalloides）。某些品种全白。&#39;, metadata={}), Document(page_content=&#39;A. phalloides，又名死亡帽，是已知所有蘑菇中最有毒的一种。&#39;, metadata={})]
</code></pre></div>
<p><strong>1.2 最大边际相关性</strong></p>
<div class="highlight"><pre><span></span><code><span class="n">question</span> <span class="o">=</span> <span class="s2">&quot;what did they say about matlab?&quot;</span>
<span class="n">docs_ss</span> <span class="o">=</span> <span class="n">vectordb</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">question</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;相似性检索：&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;docs[0]: &quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">docs_ss</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;docs[1]: &quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">docs_ss</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
<span class="nb">print</span><span class="p">()</span>

<span class="n">docs_mmr</span> <span class="o">=</span> <span class="n">vectordb</span><span class="o">.</span><span class="n">max_marginal_relevance_search</span><span class="p">(</span><span class="n">question</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MMR 检索：&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mmr[0]: &quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">docs_mmr</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MMR 检索：&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mmr[1]: &quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">docs_mmr</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>相似性检索：
docs[0]: 
those homeworks will be done in either MATLA B or in Octave, which is sort of — I 
know some people

docs[1]: 
those homeworks will be done in either MATLA B or in Octave, which is sort of — I 
know some people

MMR 检索：
mmr[0]: 
those homeworks will be done in either MATLA B or in Octave, which is sort of — I 
know some people

MMR 检索：
mmr[1]: 
algorithm then? So what’s different? How come  I was making all that noise earlier about 
least squa
</code></pre></div>
<p><strong>1.3 使用元数据</strong></p>
<div class="highlight"><pre><span></span><code><span class="n">question</span> <span class="o">=</span> <span class="s2">&quot;what did they say about regression in the third lecture?&quot;</span>

<span class="n">docs</span> <span class="o">=</span> <span class="n">vectordb</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span>
    <span class="n">question</span><span class="p">,</span>
    <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="nb">filter</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;source&quot;</span><span class="p">:</span><span class="s2">&quot;docs/cs229_lectures/MachineLearning-Lecture03.pdf&quot;</span><span class="p">}</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">metadata</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>{&#39;source&#39;: &#39;docs/cs229_lectures/MachineLearning-Lecture03.pdf&#39;, &#39;page&#39;: 0}
{&#39;source&#39;: &#39;docs/cs229_lectures/MachineLearning-Lecture03.pdf&#39;, &#39;page&#39;: 14}
{&#39;source&#39;: &#39;docs/cs229_lectures/MachineLearning-Lecture03.pdf&#39;, &#39;page&#39;: 4}
</code></pre></div>
<p><strong>1.4 使用自查询检索器</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>
<span class="kn">from</span> <span class="nn">langchain.retrievers.self_query.base</span> <span class="kn">import</span> <span class="n">SelfQueryRetriever</span>
<span class="kn">from</span> <span class="nn">langchain.chains.query_constructor.base</span> <span class="kn">import</span> <span class="n">AttributeInfo</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">metadata_field_info</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">AttributeInfo</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;source&quot;</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The lecture the chunk is from, should be one of `docs/cs229_lectures/MachineLearning-Lecture01.pdf`, `docs/cs229_lectures/MachineLearning-Lecture02.pdf`, or `docs/cs229_lectures/MachineLearning-Lecture03.pdf`&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;string&quot;</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">AttributeInfo</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;page&quot;</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The page from the lecture&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;integer&quot;</span><span class="p">,</span>
    <span class="p">),</span>
<span class="p">]</span>

<span class="n">document_content_description</span> <span class="o">=</span> <span class="s2">&quot;Lecture notes&quot;</span>
<span class="n">retriever</span> <span class="o">=</span> <span class="n">SelfQueryRetriever</span><span class="o">.</span><span class="n">from_llm</span><span class="p">(</span>
    <span class="n">llm</span><span class="p">,</span>
    <span class="n">vectordb</span><span class="p">,</span>
    <span class="n">document_content_description</span><span class="p">,</span>
    <span class="n">metadata_field_info</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="n">question</span> <span class="o">=</span> <span class="s2">&quot;what did they say about regression in the third lecture?&quot;</span>

<span class="n">docs</span> <span class="o">=</span> <span class="n">retriever</span><span class="o">.</span><span class="n">get_relevant_documents</span><span class="p">(</span><span class="n">question</span><span class="p">)</span>

<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">metadata</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>/root/autodl-tmp/env/gpt/lib/python3.10/site-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.
  warnings.warn(


query=&#39;regression&#39; filter=Comparison(comparator=&lt;Comparator.EQ: &#39;eq&#39;&gt;, attribute=&#39;source&#39;, value=&#39;docs/cs229_lectures/MachineLearning-Lecture03.pdf&#39;) limit=None
{&#39;source&#39;: &#39;docs/cs229_lectures/MachineLearning-Lecture03.pdf&#39;, &#39;page&#39;: 14}
{&#39;source&#39;: &#39;docs/cs229_lectures/MachineLearning-Lecture03.pdf&#39;, &#39;page&#39;: 0}
{&#39;source&#39;: &#39;docs/cs229_lectures/MachineLearning-Lecture03.pdf&#39;, &#39;page&#39;: 10}
{&#39;source&#39;: &#39;docs/cs229_lectures/MachineLearning-Lecture03.pdf&#39;, &#39;page&#39;: 10}
</code></pre></div>
<p><strong>1.5 压缩</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">langchain.retrievers</span> <span class="kn">import</span> <span class="n">ContextualCompressionRetriever</span>
<span class="kn">from</span> <span class="nn">langchain.retrievers.document_compressors</span> <span class="kn">import</span> <span class="n">LLMChainExtractor</span>

<span class="k">def</span> <span class="nf">pretty_print_docs</span><span class="p">(</span><span class="n">docs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;-&#39;</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;Document </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">:</span><span class="se">\n\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">d</span><span class="o">.</span><span class="n">page_content</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">docs</span><span class="p">)]))</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">compressor</span> <span class="o">=</span> <span class="n">LLMChainExtractor</span><span class="o">.</span><span class="n">from_llm</span><span class="p">(</span><span class="n">llm</span><span class="p">)</span>  <span class="c1"># 压缩器</span>

<span class="n">compression_retriever</span> <span class="o">=</span> <span class="n">ContextualCompressionRetriever</span><span class="p">(</span>
    <span class="n">base_compressor</span><span class="o">=</span><span class="n">compressor</span><span class="p">,</span>
    <span class="n">base_retriever</span><span class="o">=</span><span class="n">vectordb</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">question</span> <span class="o">=</span> <span class="s2">&quot;what did they say about matlab?&quot;</span>
<span class="n">compressed_docs</span> <span class="o">=</span> <span class="n">compression_retriever</span><span class="o">.</span><span class="n">get_relevant_documents</span><span class="p">(</span><span class="n">question</span><span class="p">)</span>
<span class="n">pretty_print_docs</span><span class="p">(</span><span class="n">compressed_docs</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Document 1:

&quot;MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it&#39;s sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.&quot;
----------------------------------------------------------------------------------------------------
Document 2:

&quot;MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it&#39;s sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.&quot;
----------------------------------------------------------------------------------------------------
Document 3:

&quot;And the student said, &quot;Oh, it was the MATLAB.&quot; So for those of you that don&#39;t know MATLAB yet, I hope you do learn it. It&#39;s not hard, and we&#39;ll actually have a short MATLAB tutorial in one of the discussion sections for those of you that don&#39;t know it.&quot;
----------------------------------------------------------------------------------------------------
Document 4:

&quot;And the student said, &quot;Oh, it was the MATLAB.&quot; So for those of you that don&#39;t know MATLAB yet, I hope you do learn it. It&#39;s not hard, and we&#39;ll actually have a short MATLAB tutorial in one of the discussion sections for those of you that don&#39;t know it.&quot;
</code></pre></div>
<p><strong>2.1 结合各种技术</strong></p>
<div class="highlight"><pre><span></span><code><span class="n">compression_retriever</span> <span class="o">=</span> <span class="n">ContextualCompressionRetriever</span><span class="p">(</span>
    <span class="n">base_compressor</span><span class="o">=</span><span class="n">compressor</span><span class="p">,</span>
    <span class="n">base_retriever</span><span class="o">=</span><span class="n">vectordb</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">(</span><span class="n">search_type</span> <span class="o">=</span> <span class="s2">&quot;mmr&quot;</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">question</span> <span class="o">=</span> <span class="s2">&quot;what did they say about matlab?&quot;</span>
<span class="n">compressed_docs</span> <span class="o">=</span> <span class="n">compression_retriever</span><span class="o">.</span><span class="n">get_relevant_documents</span><span class="p">(</span><span class="n">question</span><span class="p">)</span>
<span class="n">pretty_print_docs</span><span class="p">(</span><span class="n">compressed_docs</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Document 1:

&quot;MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it&#39;s sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.&quot;
----------------------------------------------------------------------------------------------------
Document 2:

&quot;And the student said, &quot;Oh, it was the MATLAB.&quot; So for those of you that don&#39;t know MATLAB yet, I hope you do learn it. It&#39;s not hard, and we&#39;ll actually have a short MATLAB tutorial in one of the discussion sections for those of you that don&#39;t know it.&quot;
</code></pre></div>
<p><strong>3.1 其他类型的检索</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">langchain.retrievers</span> <span class="kn">import</span> <span class="n">SVMRetriever</span>
<span class="kn">from</span> <span class="nn">langchain.retrievers</span> <span class="kn">import</span> <span class="n">TFIDFRetriever</span>
<span class="kn">from</span> <span class="nn">langchain.document_loaders</span> <span class="kn">import</span> <span class="n">PyPDFLoader</span>
<span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>

<span class="c1"># 加载PDF</span>
<span class="n">loader</span> <span class="o">=</span> <span class="n">PyPDFLoader</span><span class="p">(</span><span class="s2">&quot;docs/cs229_lectures/MachineLearning-Lecture01.pdf&quot;</span><span class="p">)</span>
<span class="n">pages</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="n">all_page_text</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">page_content</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pages</span><span class="p">]</span>
<span class="n">joined_page_text</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">all_page_text</span><span class="p">)</span>

<span class="c1"># 分割文本</span>
<span class="n">text_splitter</span> <span class="o">=</span> <span class="n">RecursiveCharacterTextSplitter</span><span class="p">(</span><span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">1500</span><span class="p">,</span><span class="n">chunk_overlap</span> <span class="o">=</span> <span class="mi">150</span><span class="p">)</span>
<span class="n">splits</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="o">.</span><span class="n">split_text</span><span class="p">(</span><span class="n">joined_page_text</span><span class="p">)</span>

<span class="c1"># 检索</span>
<span class="n">svm_retriever</span> <span class="o">=</span> <span class="n">SVMRetriever</span><span class="o">.</span><span class="n">from_texts</span><span class="p">(</span><span class="n">splits</span><span class="p">,</span> <span class="n">embedding</span><span class="p">)</span>
<span class="n">tfidf_retriever</span> <span class="o">=</span> <span class="n">TFIDFRetriever</span><span class="o">.</span><span class="n">from_texts</span><span class="p">(</span><span class="n">splits</span><span class="p">)</span>

<span class="n">question</span> <span class="o">=</span> <span class="s2">&quot;What are major topics for this class?&quot;</span>  <span class="c1"># 这门课的主要主题是什么？</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;SVM:&quot;</span><span class="p">)</span>
<span class="n">docs_svm</span> <span class="o">=</span> <span class="n">svm_retriever</span><span class="o">.</span><span class="n">get_relevant_documents</span><span class="p">(</span><span class="n">question</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">docs_svm</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">question</span> <span class="o">=</span> <span class="s2">&quot;what did they say about matlab?&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TF-IDF:&quot;</span><span class="p">)</span>
<span class="n">docs_tfidf</span> <span class="o">=</span> <span class="n">tfidf_retriever</span><span class="o">.</span><span class="n">get_relevant_documents</span><span class="p">(</span><span class="n">question</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">docs_tfidf</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>SVM:
page_content=&quot;let me just check what questions you have righ t now. So if there are no questions, I&#39;ll just \nclose with two reminders, which are after class today or as you start to talk with other \npeople in this class, I just encourage you again to start to form project partners, to try to \nfind project partners to do your project with. And also, this is a good time to start forming \nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \nencourage you to try to star t to do both of those today, okay? Form study groups, and try \nto find two other project partners.  \nSo thank you. I&#39;m looking forward to teaching this class, and I&#39;ll see you in a couple of \ndays.   [End of Audio]  \nDuration: 69 minutes&quot; metadata={}
TF-IDF:
page_content=&quot;Saxena and Min Sun here did, wh ich is given an image like this, right? This is actually a \npicture taken of the Stanford campus. You can apply that sort of cl ustering algorithm and \ngroup the picture into regions. Let me actually blow that up so that you can see it more \nclearly. Okay. So in the middle, you see the lines sort of groupi ng the image together, \ngrouping the image into [inaudible] regions.  \nAnd what Ashutosh and Min did was they then  applied the learning algorithm to say can \nwe take this clustering and us e it to build a 3D model of the world? And so using the \nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \nworld looks like so that they could come up with a 3D model that you can sort of fly \nthrough, okay? Although many people used to th ink it&#39;s not possible to take a single \nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \nalgorithm is the first step. They were able to.  \nI&#39;ll just show you one more example. I like this  because it&#39;s a picture of Stanford with our \nbeautiful Stanford campus. So again, taking th e same sort of clustering algorithms, taking \nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \nregions. And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.  You can sort of walk  into the ceiling, look&quot; metadata={}
</code></pre></div>

  <hr>
<div class="md-source-file">
  <small>
    
      最后更新:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2023</span>
      
        <br>
        创建日期:
        <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2023</span>
      
    
  </small>
</div>





                
              </article>
            </div>
          
          
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="页脚" >
        
          
          <a href="../4.%20%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E8%AF%8D%E5%90%91%E9%87%8F%20Vectorstores%20and%20Embeddings/" class="md-footer__link md-footer__link--prev" aria-label="上一页: 第四章 向量数据库与词向量(Vectorstores and Embeddings)">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                上一页
              </span>
              <div class="md-ellipsis">
                第四章 向量数据库与词向量(Vectorstores and Embeddings)
              </div>
            </div>
          </a>
        
        
          
          <a href="../6.%20%E9%97%AE%E7%AD%94%20Question%20Answering/" class="md-footer__link md-footer__link--next" aria-label="下一页: 第六章 问答">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                下一页
              </span>
              <div class="md-ellipsis">
                第六章 问答
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2023 Ean Yang
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/YQisme" target="_blank" rel="noopener" title="github主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://space.bilibili.com/244185393?spm_id_from=333.788.0.0" target="_blank" rel="noopener" title="b站主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M488.6 104.1c16.7 18.1 24.4 39.7 23.3 65.7v202.4c-.4 26.4-9.2 48.1-26.5 65.1-17.2 17-39.1 25.9-65.5 26.7H92.02c-26.45-.8-48.21-9.8-65.28-27.2C9.682 419.4.767 396.5 0 368.2V169.8c.767-26 9.682-47.6 26.74-65.7C43.81 87.75 65.57 78.77 92.02 78h29.38L96.05 52.19c-5.75-5.73-8.63-13-8.63-21.79 0-8.8 2.88-16.06 8.63-21.797C101.8 2.868 109.1 0 117.9 0s16.1 2.868 21.9 8.603L213.1 78h88l74.5-69.397C381.7 2.868 389.2 0 398 0c8.8 0 16.1 2.868 21.9 8.603 5.7 5.737 8.6 12.997 8.6 21.797 0 8.79-2.9 16.06-8.6 21.79L394.6 78h29.3c26.4.77 48 9.75 64.7 26.1zm-38.8 69.7c-.4-9.6-3.7-17.4-10.7-23.5-5.2-6.1-14-9.4-22.7-9.8H96.05c-9.59.4-17.45 3.7-23.58 9.8-6.14 6.1-9.4 13.9-9.78 23.5v194.4c0 9.2 3.26 17 9.78 23.5s14.38 9.8 23.58 9.8H416.4c9.2 0 17-3.3 23.3-9.8 6.3-6.5 9.7-14.3 10.1-23.5V173.8zm-264.3 42.7c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.2 6.3-14 9.5-23.6 9.5-9.6 0-17.5-3.2-23.6-9.5-6.1-6.3-9.4-14-9.8-23.2v-33.3c.4-9.1 3.8-16.9 10.1-23.2 6.3-6.3 13.2-9.6 23.3-10 9.2.4 17 3.7 23.3 10zm191.5 0c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.1 6.3-14 9.5-23.6 9.5-9.6 0-17.4-3.2-23.6-9.5-7-6.3-9.4-14-9.7-23.2v-33.3c.3-9.1 3.7-16.9 10-23.2 6.3-6.3 14.1-9.6 23.3-10 9.2.4 17 3.7 23.3 10z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://eanyang7.com" target="_blank" rel="noopener" title="个人主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M112 48a48 48 0 1 1 96 0 48 48 0 1 1-96 0zm40 304v128c0 17.7-14.3 32-32 32s-32-14.3-32-32V256.9l-28.6 47.6c-9.1 15.1-28.8 20-43.9 10.9s-20-28.8-10.9-43.9l58.3-97c17.4-28.9 48.6-46.6 82.3-46.6h29.7c33.7 0 64.9 17.7 82.3 46.6l58.3 97c9.1 15.1 4.2 34.8-10.9 43.9s-34.8 4.2-43.9-10.9L232 256.9V480c0 17.7-14.3 32-32 32s-32-14.3-32-32V352h-16z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "navigation.instant.progress", "navigation.tracking", "navigation.prune", "navigation.top", "toc.follow", "header.autohide", "navigation.footer", "search.suggest", "search.highlight", "search.share", "content.action.edit", "content.action.view", "content.code.copy"], "search": "../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.6c14ae12.min.js"></script>
      
    
  </body>
</html>