
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="面向开发者的 LLM 入门教程，吴恩达大模型系列课程中文版">
      
      
        <meta name="author" content="Ean Yang">
      
      
        <link rel="canonical" href="https://eanyang7.github.io/prompt-engineering-for-developers/02-%E6%90%AD%E5%BB%BA%E5%9F%BA%E4%BA%8E%20ChatGPT%20%E7%9A%84%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/2.%20%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%8C%E6%8F%90%E9%97%AE%E8%8C%83%E5%BC%8F%E4%B8%8E%20Token%20Language%20Models%2C%20the%20Chat%20Format%20and%20Tokens/">
      
      
        <link rel="prev" href="../11.%E6%80%BB%E7%BB%93%20conclusion/">
      
      
        <link rel="next" href="../3.%20%E8%AF%84%E4%BC%B0%E8%BE%93%E5%85%A5-%E5%88%86%E7%B1%BB%20Classification/">
      
      
      <link rel="icon" href="../../assets/favicon.jpg">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.12">
    
    
      
        <title>第二章 语言模型，提问范式与 Token - 面向开发者的 LLM 入门教程</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.fad675c6.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.356b1318.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#token" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../.." title="面向开发者的 LLM 入门教程" class="md-header__button md-logo" aria-label="面向开发者的 LLM 入门教程" data-md-component="logo">
      
  <img src="../../assets/logo.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            面向开发者的 LLM 入门教程
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              第二章 语言模型，提问范式与 Token
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple"  aria-label="切换为暗黑模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换为暗黑模式" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="deep-purple" data-md-color-accent="red"  aria-label="切换为浅色模式"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="切换为浅色模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
      </label>
    
  
</form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="分享" aria-label="分享" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/EanYang7/prompt-engineering-for-developers" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    github仓库
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="面向开发者的 LLM 入门教程" class="md-nav__button md-logo" aria-label="面向开发者的 LLM 入门教程" data-md-component="logo">
      
  <img src="../../assets/logo.jpg" alt="logo">

    </a>
    面向开发者的 LLM 入门教程
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/EanYang7/prompt-engineering-for-developers" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    github仓库
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    面向开发者的 LLM 入门课程
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../%E5%89%8D%E8%A8%80/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    前言
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    环境配置
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../01-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/1.%20%E7%AE%80%E4%BB%8B%20Introduction/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    01 面向开发者的提示工程
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
    
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    02 搭建基于 ChatGPT 的问答系统
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            02 搭建基于 ChatGPT 的问答系统
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../1.%20%E7%AE%80%E4%BB%8B%20Introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第一章 简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../10.%20%E8%AF%84%E4%BC%B0%EF%BC%88%E4%B8%8B%EF%BC%89Evaluation-part2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第十章 评估（下）——当不存在一个简单的正确答案时
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../11.%E6%80%BB%E7%BB%93%20conclusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第十一章 总结
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    第二章 语言模型，提问范式与 Token
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    第二章 语言模型，提问范式与 Token
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      一、语言模型
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tokens" class="md-nav__link">
    <span class="md-ellipsis">
      二、Tokens
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#helper-function" class="md-nav__link">
    <span class="md-ellipsis">
      三、Helper function 辅助函数 (提问范式)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      四、英文版
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../3.%20%E8%AF%84%E4%BC%B0%E8%BE%93%E5%85%A5-%E5%88%86%E7%B1%BB%20Classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第三章 评估输入——分类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../4.%20%E6%A3%80%E6%9F%A5%E8%BE%93%E5%85%A5-%E7%9B%91%E7%9D%A3%20Moderation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第四章 检查输入 - 审核
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../5.%20%E5%A4%84%E7%90%86%E8%BE%93%E5%85%A5-%E6%80%9D%E7%BB%B4%E9%93%BE%E6%8E%A8%E7%90%86%20Chain%20of%20Thought%20Reasoning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第五章 处理输入-思维链推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../6.%20%E5%A4%84%E7%90%86%E8%BE%93%E5%85%A5-%E9%93%BE%E5%BC%8F%20Prompt%20Chaining%20Prompts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第六章 处理输入-链式
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../7.%20%E6%A3%80%E6%9F%A5%E7%BB%93%E6%9E%9C%20Check%20Outputs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第七章 检查结果
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../8.%20%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B8%A6%E8%AF%84%E4%BC%B0%E7%9A%84%E7%AB%AF%E5%88%B0%E7%AB%AF%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F%20Evaluation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第八章 搭建一个带评估的端到端问答系统
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../9.%20%E8%AF%84%E4%BC%B0%EF%BC%88%E4%B8%8A%EF%BC%89%20Evaluation-part1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第九章 评估（上）——存在一个简单的正确答案时
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../readme/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第二部分 搭建基于 ChatGPT 的问答系统
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../03-%E4%BD%BF%E7%94%A8%20LangChain%20%E5%BC%80%E5%8F%91%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F/1.%20%E7%AE%80%E4%BB%8B%20Introduction/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    03 使用 LangChain 开发应用程序
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../04-%E4%BD%BF%E7%94%A8%20LangChain%20%E8%AE%BF%E9%97%AE%E4%B8%AA%E4%BA%BA%E6%95%B0%E6%8D%AE/1.%20%E7%AE%80%E4%BB%8B%20Introduction/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    04 使用 LangChain 访问个人数据
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      一、语言模型
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tokens" class="md-nav__link">
    <span class="md-ellipsis">
      二、Tokens
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#helper-function" class="md-nav__link">
    <span class="md-ellipsis">
      三、Helper function 辅助函数 (提问范式)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      四、英文版
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/EanYang7/prompt-engineering-for-developers/tree/main/docs/02-搭建基于 ChatGPT 的问答系统/2. 语言模型，提问范式与 Token Language Models, the Chat Format and Tokens.md" title="编辑此页" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/EanYang7/prompt-engineering-for-developers/tree/main/docs/02-搭建基于 ChatGPT 的问答系统/2. 语言模型，提问范式与 Token Language Models, the Chat Format and Tokens.md" title="查看本页的源代码" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5Z"/></svg>
    </a>
  


<h1 id="token">第二章 语言模型，提问范式与 Token<a class="headerlink" href="#token" title="Permanent link">⚓︎</a></h1>
<p>在本章中，我们将和您分享大型语言模型（LLM）的工作原理、训练方式以及分词器（tokenizer）等细节对 LLM 输出的影响。我们还将介绍 LLM 的提问范式（chat format），这是一种指定系统消息（system message）和用户消息（user message）的方式，让您了解如何利用这种能力。</p>
<h2 id="_1">一、语言模型<a class="headerlink" href="#_1" title="Permanent link">⚓︎</a></h2>
<p>大语言模型（LLM）是通过预测下一个词的监督学习方式进行训练的。具体来说，首先准备一个包含数百亿甚至更多词的大规模文本数据集。然后，可以从这些文本中提取句子或句子片段作为模型输入。模型会根据当前输入 Context 预测下一个词的概率分布。通过不断比较模型预测和实际的下一个词，并更新模型参数最小化两者差异,语言模型逐步掌握了语言的规律，学会了预测下一个词。</p>
<p>在训练过程中,研究人员会准备大量句子或句子片段作为训练样本,要求模型一次次预测下一个词，通过反复训练促使模型参数收敛，使其预测能力不断提高。经过在海量文本数据集上的训练，语言模型可以达到十分准确地预测下一个词的效果。这种<strong>以预测下一个词为训练目标的方法使得语言模型获得强大的语言生成能力</strong>。</p>
<p>大型语言模型主要可以分为两类:基础语言模型和指令调优语言模型。</p>
<p><strong>基础语言模型</strong>（Base LLM）通过反复预测下一个词来训练的方式进行训练，没有明确的目标导向。因此，如果给它一个开放式的 prompt ，它可能会通过自由联想生成戏剧化的内容。而对于具体的问题，基础语言模型也可能给出与问题无关的回答。例如，给它一个 Prompt ，比如”中国的首都是哪里？“，很可能它数据中有一段互联网上关于中国的测验问题列表。这时，它可能会用“中国最大的城市是什么？中国的人口是多少？”等等来回答这个问题。但实际上，您只是想知道中国的首都是什么，而不是列举所有这些问题。</p>
<p>相比之下，<strong>指令微调的语言模型</strong>（Instruction Tuned LLM）则进行了专门的训练，以便更好地理解问题并给出符合指令的回答。例如，对“中国的首都是哪里？”这个问题，经过微调的语言模型很可能直接回答“中国的首都是北京”，而不是生硬地列出一系列相关问题。<strong>指令微调使语言模型更加适合任务导向的对话应用</strong>。它可以生成遵循指令的语义准确的回复，而非自由联想。因此，许多实际应用已经采用指令调优语言模型。熟练掌握指令微调的工作机制，是开发者实现语言模型应用的重要一步。</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">tool</span> <span class="kn">import</span> <span class="n">get_completion</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">get_completion</span><span class="p">(</span><span class="s2">&quot;中国的首都是哪里？&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>中国的首都是北京。
</code></pre></div>
<p>那么，如何将基础语言模型转变为指令微调语言模型呢？</p>
<p>这也就是训练一个指令微调语言模型（例如ChatGPT）的过程。
首先，在大规模文本数据集上进行<strong>无监督预训练</strong>，获得基础语言模型。
这一步需要使用数千亿词甚至更多的数据，在大型超级计算系统上可能需要数月时间。
之后，使用包含指令及对应回复示例的小数据集对基础模型进行<strong>有监督 fine-tune</strong>，这让模型逐步学会遵循指令生成输出，可以通过雇佣承包商构造适合的训练示例。
接下来，为了提高语言模型输出的质量，常见的方法是让人类对许多不同输出进行评级，例如是否有用、是否真实、是否无害等。
然后，您可以进一步调整语言模型，增加生成高评级输出的概率。这通常使用<strong>基于人类反馈的强化学习</strong>（RLHF）技术来实现。
相较于训练基础语言模型可能需要数月的时间，从基础语言模型到指令微调语言模型的转变过程可能只需要数天时间，使用较小规模的数据集和计算资源。</p>
<h2 id="tokens">二、Tokens<a class="headerlink" href="#tokens" title="Permanent link">⚓︎</a></h2>
<p>到目前为止对 LLM 的描述中，我们将其描述为一次预测一个单词，但实际上还有一个更重要的技术细节。即 <strong><code>LLM 实际上并不是重复预测下一个单词，而是重复预测下一个 token</code></strong> 。对于一个句子，语言模型会先使用分词器将其拆分为一个个 token ，而不是原始的单词。对于生僻词，可能会拆分为多个 token 。这样可以大幅降低字典规模，提高模型训练和推断的效率。例如，对于 "Learning new things is fun!" 这句话，每个单词都被转换为一个 token ，而对于较少使用的单词，如 "Prompting as powerful developer tool"，单词 "prompting" 会被拆分为三个 token，即"prom"、"pt"和"ing"。</p>
<div class="highlight"><pre><span></span><code><span class="c1"># 为了更好展示效果，这里就没有翻译成中文的 Prompt</span>
<span class="c1"># 注意这里的字母翻转出现了错误，吴恩达老师正是通过这个例子来解释 token 的计算方式</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">get_completion</span><span class="p">(</span><span class="s2">&quot;Take the letters in lollipop </span><span class="se">\</span>
<span class="s2">and reverse them&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>The reversed letters of &quot;lollipop&quot; are &quot;pillipol&quot;.
</code></pre></div>
<p>但是，"lollipop" 反过来应该是 "popillol"。</p>
<p>但<code>分词方式也会对语言模型的理解能力产生影响</code>。当您要求 ChatGPT 颠倒 "lollipop" 的字母时，由于分词器（tokenizer） 将 "lollipop" 分解为三个 token，即 "l"、"oll"、"ipop"，因此 ChatGPT 难以正确输出字母的顺序。这时可以通过在字母间添加分隔，让每个字母成为一个token，以帮助模型准确理解词中的字母顺序。</p>
<div class="highlight"><pre><span></span><code><span class="n">response</span> <span class="o">=</span> <span class="n">get_completion</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;Take the letters in </span><span class="se">\</span>
<span class="s2">l-o-l-l-i-p-o-p and reverse them&quot;&quot;&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>p-o-p-i-l-l-o-l
</code></pre></div>
<p>因此,语言模型以 token 而非原词为单位进行建模，这一关键细节对分词器的选择及处理会产生重大影响。开发者需要注意分词方式对语言理解的影响，以发挥语言模型最大潜力。</p>
<p>❗❗❗ 对于英文输入，一个 token 一般对应 4 个字符或者四分之三个单词；对于中文输入，一个 token 一般对应一个或半个词。不同模型有不同的 token 限制，需要注意的是，这里的 token 限制是<strong>输入的 Prompt 和输出的 completion 的 token 数之和</strong>，因此输入的 Prompt 越长，能输出的 completion 的上限就越低。 ChatGPT3.5-turbo 的 token 上限是 4096。</p>
<p><img alt="Tokens.png" src="../../figures/C2/tokens.png" /></p>
<div align='center'>图 2.2.1 Token 示例</div>

<h2 id="helper-function">三、Helper function 辅助函数 (提问范式)<a class="headerlink" href="#helper-function" title="Permanent link">⚓︎</a></h2>
<p>语言模型提供了专门的“提问格式”，可以更好地发挥其理解和回答问题的能力。本章将详细介绍这种格式的使用方法。</p>
<p><img alt="Chat-format.png" src="../../figures/C2/chat-format.png" /></p>
<div align='center'>图 2.2.2 Chat 格式 </div>

<p>这种提问格式区分了“系统消息”和“用户消息”两个部分。系统消息是我们向语言模型传达讯息的语句，用户消息则是模拟用户的问题。例如:
<div class="highlight"><pre><span></span><code>系统消息:你是一个能够回答各类问题的助手。

用户消息:太阳系有哪些行星?
</code></pre></div>
通过这种提问格式，我们可以明确地角色扮演，让语言模型理解自己就是助手这个角色，需要回答问题。这可以减少无效输出，帮助其生成针对性强的回复。本章将通过OpenAI提供的辅助函数，来演示如何正确使用这种提问格式与语言模型交互。掌握这一技巧可以大幅提升我们与语言模型对话的效果，构建更好的问答系统。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">openai</span>
<span class="k">def</span> <span class="nf">get_completion_from_messages</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> 
                                 <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">,</span> 
                                 <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
                                 <span class="n">max_tokens</span><span class="o">=</span><span class="mi">500</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    封装一个支持更多参数的自定义访问 OpenAI GPT3.5 的函数</span>

<span class="sd">    参数: </span>
<span class="sd">    messages: 这是一个消息列表，每个消息都是一个字典，包含 role(角色）和 content(内容)。角色可以是&#39;system&#39;、&#39;user&#39; 或 &#39;assistant’，内容是角色的消息。</span>
<span class="sd">    model: 调用的模型，默认为 gpt-3.5-turbo(ChatGPT)，有内测资格的用户可以选择 gpt-4</span>
<span class="sd">    temperature: 这决定模型输出的随机程度，默认为0，表示输出将非常确定。增加温度会使输出更随机。</span>
<span class="sd">    max_tokens: 这决定模型输出的最大的 token 数。</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
        <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span> <span class="c1"># 这决定模型输出的随机程度</span>
        <span class="n">max_tokens</span><span class="o">=</span><span class="n">max_tokens</span><span class="p">,</span> <span class="c1"># 这决定模型输出的最大的 token 数</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="p">[</span><span class="s2">&quot;content&quot;</span><span class="p">]</span>
</code></pre></div>
<p>在上面，我们封装一个支持更多参数的自定义访问 OpenAI GPT3.5 的函数 get_completion_from_messages 。在以后的章节中，我们将把这个函数封装在 tool 包中。</p>
<div class="highlight"><pre><span></span><code><span class="n">messages</span> <span class="o">=</span>  <span class="p">[</span>  
<span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span><span class="s1">&#39;system&#39;</span><span class="p">,</span> 
 <span class="s1">&#39;content&#39;</span><span class="p">:</span><span class="s1">&#39;你是一个助理， 并以 Seuss 苏斯博士的风格作出回答。&#39;</span><span class="p">},</span>    
<span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span><span class="s1">&#39;user&#39;</span><span class="p">,</span> 
 <span class="s1">&#39;content&#39;</span><span class="p">:</span><span class="s1">&#39;就快乐的小鲸鱼为主题给我写一首短诗&#39;</span><span class="p">},</span>  
<span class="p">]</span> 
<span class="n">response</span> <span class="o">=</span> <span class="n">get_completion_from_messages</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>在大海的广漠深处，
有一只小鲸鱼欢乐自由；
它的身上披着光彩斑斓的袍，
跳跃飞舞在波涛的傍。

它不知烦恼，只知欢快起舞，
阳光下闪亮，活力无边疆；
它的微笑如同璀璨的星辰，
为大海增添一片美丽的光芒。

大海是它的天地，自由是它的伴，
快乐是它永恒的干草堆；
在浩瀚无垠的水中自由畅游，
小鲸鱼的欢乐让人心中温暖。

所以啊，让我们感受那欢乐的鲸鱼，
尽情舞动，让快乐自由流；
无论何时何地，都保持微笑，
像鲸鱼一样，活出自己的光芒。
</code></pre></div>
<p>在上面，我们使用了提问范式与语言模型进行对话：
<div class="highlight"><pre><span></span><code>系统消息:你是一个助理， 并以 Seuss 苏斯博士的风格作出回答。

用户消息:就快乐的小鲸鱼为主题给我写一首短诗
</code></pre></div></p>
<p>下面让我们再看一个例子：</p>
<div class="highlight"><pre><span></span><code><span class="c1"># 长度控制</span>
<span class="n">messages</span> <span class="o">=</span>  <span class="p">[</span>  
<span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span><span class="s1">&#39;system&#39;</span><span class="p">,</span>
 <span class="s1">&#39;content&#39;</span><span class="p">:</span><span class="s1">&#39;你的所有答复只能是一句话&#39;</span><span class="p">},</span>    
<span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span><span class="s1">&#39;user&#39;</span><span class="p">,</span>
 <span class="s1">&#39;content&#39;</span><span class="p">:</span><span class="s1">&#39;写一个关于快乐的小鲸鱼的故事&#39;</span><span class="p">},</span>  
<span class="p">]</span> 
<span class="n">response</span> <span class="o">=</span> <span class="n">get_completion_from_messages</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">temperature</span> <span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>从小鲸鱼的快乐笑声中，我们学到了无论遇到什么困难，快乐始终是最好的解药。
</code></pre></div>
<p>将以上两个例子结合起来：</p>
<div class="highlight"><pre><span></span><code><span class="c1"># 以上结合</span>
<span class="n">messages</span> <span class="o">=</span>  <span class="p">[</span>  
<span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span><span class="s1">&#39;system&#39;</span><span class="p">,</span>
 <span class="s1">&#39;content&#39;</span><span class="p">:</span><span class="s1">&#39;你是一个助理， 并以 Seuss 苏斯博士的风格作出回答，只回答一句话&#39;</span><span class="p">},</span>    
<span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span><span class="s1">&#39;user&#39;</span><span class="p">,</span>
 <span class="s1">&#39;content&#39;</span><span class="p">:</span><span class="s1">&#39;写一个关于快乐的小鲸鱼的故事&#39;</span><span class="p">},</span>
<span class="p">]</span> 
<span class="n">response</span> <span class="o">=</span> <span class="n">get_completion_from_messages</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">temperature</span> <span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>在海洋的深处住着一只小鲸鱼，它总是展开笑容在水中翱翔，快乐无边的时候就会跳起华丽的舞蹈。
</code></pre></div>
<p>我们在下面定义了一个 get_completion_and_token_count 函数，它实现了调用 OpenAI 的 模型生成聊天回复， 并返回生成的回复内容以及使用的 token 数量。</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">get_completion_and_token_count</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> 
                                   <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">,</span> 
                                   <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
                                   <span class="n">max_tokens</span><span class="o">=</span><span class="mi">500</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    使用 OpenAI 的 GPT-3 模型生成聊天回复，并返回生成的回复内容以及使用的 token 数量。</span>

<span class="sd">    参数:</span>
<span class="sd">    messages: 聊天消息列表。</span>
<span class="sd">    model: 使用的模型名称。默认为&quot;gpt-3.5-turbo&quot;。</span>
<span class="sd">    temperature: 控制生成回复的随机性。值越大，生成的回复越随机。默认为 0。</span>
<span class="sd">    max_tokens: 生成回复的最大 token 数量。默认为 500。</span>

<span class="sd">    返回:</span>
<span class="sd">    content: 生成的回复内容。</span>
<span class="sd">    token_dict: 包含&#39;prompt_tokens&#39;、&#39;completion_tokens&#39;和&#39;total_tokens&#39;的字典，分别表示提示的 token 数量、生成的回复的 token 数量和总的 token 数量。</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
        <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span> 
        <span class="n">max_tokens</span><span class="o">=</span><span class="n">max_tokens</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">content</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="p">[</span><span class="s2">&quot;content&quot;</span><span class="p">]</span>

    <span class="n">token_dict</span> <span class="o">=</span> <span class="p">{</span>
<span class="s1">&#39;prompt_tokens&#39;</span><span class="p">:</span><span class="n">response</span><span class="p">[</span><span class="s1">&#39;usage&#39;</span><span class="p">][</span><span class="s1">&#39;prompt_tokens&#39;</span><span class="p">],</span>
<span class="s1">&#39;completion_tokens&#39;</span><span class="p">:</span><span class="n">response</span><span class="p">[</span><span class="s1">&#39;usage&#39;</span><span class="p">][</span><span class="s1">&#39;completion_tokens&#39;</span><span class="p">],</span>
<span class="s1">&#39;total_tokens&#39;</span><span class="p">:</span><span class="n">response</span><span class="p">[</span><span class="s1">&#39;usage&#39;</span><span class="p">][</span><span class="s1">&#39;total_tokens&#39;</span><span class="p">],</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">content</span><span class="p">,</span> <span class="n">token_dict</span>
</code></pre></div>
<p>下面，让我们调用刚创建的 get_completion_and_token_count 函数，使用提问范式去进行对话：</p>
<div class="highlight"><pre><span></span><code><span class="n">messages</span> <span class="o">=</span>  <span class="p">[</span>  
<span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span><span class="s1">&#39;system&#39;</span><span class="p">,</span> 
 <span class="s1">&#39;content&#39;</span><span class="p">:</span><span class="s1">&#39;你是一个助理， 并以 Seuss 苏斯博士的风格作出回答。&#39;</span><span class="p">},</span>    
<span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span><span class="s1">&#39;user&#39;</span><span class="p">,</span> 
 <span class="s1">&#39;content&#39;</span><span class="p">:</span><span class="s1">&#39;就快乐的小鲸鱼为主题给我写一首短诗&#39;</span><span class="p">},</span>  
<span class="p">]</span> 
<span class="n">response</span><span class="p">,</span> <span class="n">token_dict</span> <span class="o">=</span> <span class="n">get_completion_and_token_count</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>在大海的深处，有一只小鲸鱼，
它快乐地游来游去，像一只小小的鱼。
它的皮肤光滑又湛蓝，像天空中的云朵，
它的眼睛明亮又温柔，像夜空中的星星。

它和海洋为伴，一起跳跃又嬉戏，
它和鱼儿们一起，快乐地游来游去。
它喜欢唱歌又跳舞，给大家带来欢乐，
它的声音甜美又动听，像音乐中的节奏。

小鲸鱼是快乐的使者，给世界带来笑声，
它的快乐是无穷的，永远不会停止。
让我们跟随小鲸鱼，一起快乐地游来游去，
在大海的宽阔中，找到属于我们的快乐之地。
</code></pre></div>
<p>打印 token 字典看一下使用的 token 数量，我们可以看到：提示使用了67个 token ，生成的回复使用了293个 token ，总的使用 token 数量是360。</p>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">token_dict</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>{&#39;prompt_tokens&#39;: 67, &#39;completion_tokens&#39;: 293, &#39;total_tokens&#39;: 360}
</code></pre></div>
<p>在AI应用开发领域，Prompt技术的出现无疑是一场革命性的变革。然而，这种变革的重要性并未得到广泛的认知和重视。传统的监督机器学习工作流程中，构建一个能够分类餐厅评论为正面或负面的分类器，需要耗费大量的时间和资源。</p>
<p>首先，我们需要收集并标注大量带有标签的数据。这可能需要数周甚至数月的时间才能完成。接着，我们需要选择合适的开源模型，并进行模型的调整和评估。这个过程可能需要几天、几周，甚至几个月的时间。最后，我们还需要将模型部署到云端，并让它运行起来，才能最终调用您的模型。整个过程通常需要一个团队数月时间才能完成。</p>
<p>相比之下，基于 Prompt 的机器学习方法大大简化了这个过程。当我们有一个文本应用时，只需要提供一个简单的 Prompt ，这个过程可能只需要几分钟，如果需要多次迭代来得到有效的 Prompt 的话，最多几个小时即可完成。在几天内(尽管实际情况通常是几个小时)，我们就可以通过API调用来运行模型，并开始使用。一旦我们达到了这个步骤，只需几分钟或几个小时，就可以开始调用模型进行推理。因此，以前可能需要花费六个月甚至一年时间才能构建的应用，现在只需要几分钟或几个小时，最多是几天的时间，就可以使用Prompt构建起来。这种方法正在极大地改变AI应用的快速构建方式。</p>
<p>需要注意的是，这种方法适用于许多非结构化数据应用，特别是文本应用，以及越来越多的视觉应用，尽管目前的视觉技术仍在发展中。但它并不适用于结构化数据应用，也就是那些处理 Excel 电子表格中大量数值的机器学习应用。然而，对于适用于这种方法的应用，AI组件可以被快速构建，并且正在改变整个系统的构建工作流。构建整个系统可能仍然需要几天、几周或更长时间，但至少这部分可以更快地完成。</p>
<p>总的来说， Prompt 技术的出现正在改变AI应用开发的范式，使得开发者能够更快速、更高效地构建和部署应用。然而，我们也需要认识到这种技术的局限性，以便更好地利用它来推动AI应用的发展。</p>
<p>下一个章中，我们将展示如何利用这些组件来评估客户服务助手的输入。
这将是本课程中构建在线零售商客户服务助手的更完整示例的一部分。</p>
<h2 id="_2">四、英文版<a class="headerlink" href="#_2" title="Permanent link">⚓︎</a></h2>
<p><strong>1.1 语言模型</strong></p>
<div class="highlight"><pre><span></span><code><span class="n">response</span> <span class="o">=</span> <span class="n">get_completion</span><span class="p">(</span><span class="s2">&quot;What is the capital of China?&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>The capital of China is Beijing.
</code></pre></div>
<p><strong>2.1 Tokens</strong></p>
<div class="highlight"><pre><span></span><code><span class="n">response</span> <span class="o">=</span> <span class="n">get_completion</span><span class="p">(</span><span class="s2">&quot;Take the letters in lollipop and reverse them&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>The reversed letters of &quot;lollipop&quot; are &quot;pillipol&quot;.
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">response</span> <span class="o">=</span> <span class="n">get_completion</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;Take the letters in </span><span class="se">\</span>
<span class="s2">l-o-l-l-i-p-o-p and reverse them&quot;&quot;&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>p-o-p-i-l-l-o-l
</code></pre></div>
<p><strong>3.1 提问范式</strong></p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">get_completion_from_messages</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> 
                                 <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">,</span> 
                                 <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
                                 <span class="n">max_tokens</span><span class="o">=</span><span class="mi">500</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    封装一个支持更多参数的自定义访问 OpenAI GPT3.5 的函数</span>

<span class="sd">    参数: </span>
<span class="sd">    messages: 这是一个消息列表，每个消息都是一个字典，包含 role(角色）和 content(内容)。角色可以是&#39;system&#39;、&#39;user&#39; 或 &#39;assistant’，内容是角色的消息。</span>
<span class="sd">    model: 调用的模型，默认为 gpt-3.5-turbo(ChatGPT)，有内测资格的用户可以选择 gpt-4</span>
<span class="sd">    temperature: 这决定模型输出的随机程度，默认为0，表示输出将非常确定。增加温度会使输出更随机。</span>
<span class="sd">    max_tokens: 这决定模型输出的最大的 token 数。</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
        <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span> <span class="c1"># 这决定模型输出的随机程度</span>
        <span class="n">max_tokens</span><span class="o">=</span><span class="n">max_tokens</span><span class="p">,</span> <span class="c1"># 这决定模型输出的最大的 token 数</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="p">[</span><span class="s2">&quot;content&quot;</span><span class="p">]</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">messages</span> <span class="o">=</span>  <span class="p">[</span>  
<span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span><span class="s1">&#39;system&#39;</span><span class="p">,</span> 
 <span class="s1">&#39;content&#39;</span><span class="p">:</span><span class="s2">&quot;&quot;&quot;You are an assistant who</span><span class="se">\</span>
<span class="s2"> responds in the style of Dr Seuss.&quot;&quot;&quot;</span><span class="p">},</span>    
<span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span><span class="s1">&#39;user&#39;</span><span class="p">,</span> 
 <span class="s1">&#39;content&#39;</span><span class="p">:</span><span class="s2">&quot;&quot;&quot;write me a very short poem</span><span class="se">\</span>
<span class="s2"> about a happy carrot&quot;&quot;&quot;</span><span class="p">},</span>  
<span class="p">]</span> 
<span class="n">response</span> <span class="o">=</span> <span class="n">get_completion_from_messages</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Oh, a carrot so happy and bright,
With a vibrant orange hue, oh what a sight!
It grows in the garden, so full of delight,
A veggie so cheery, it shines in the light.

Its green leaves wave with such joyful glee,
As it dances and sways, so full of glee.
With a crunch when you bite, so wonderfully sweet,
This happy little carrot is quite a treat!

From the soil, it sprouts, reaching up to the sky,
With a joyous spirit, it can&#39;t help but try.
To bring smiles to faces and laughter to hearts,
This happy little carrot, a work of art!
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># length</span>
<span class="n">messages</span> <span class="o">=</span>  <span class="p">[</span>  
<span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span><span class="s1">&#39;system&#39;</span><span class="p">,</span>
 <span class="s1">&#39;content&#39;</span><span class="p">:</span><span class="s1">&#39;All your responses must be </span><span class="se">\</span>
<span class="s1">one sentence long.&#39;</span><span class="p">},</span>    
<span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span><span class="s1">&#39;user&#39;</span><span class="p">,</span>
 <span class="s1">&#39;content&#39;</span><span class="p">:</span><span class="s1">&#39;write me a story about a happy carrot&#39;</span><span class="p">},</span>  
<span class="p">]</span> 
<span class="n">response</span> <span class="o">=</span> <span class="n">get_completion_from_messages</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">temperature</span> <span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Once upon a time, there was a happy carrot named Crunch who lived in a beautiful vegetable garden.
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># combined</span>
<span class="n">messages</span> <span class="o">=</span>  <span class="p">[</span>  
<span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span><span class="s1">&#39;system&#39;</span><span class="p">,</span>
 <span class="s1">&#39;content&#39;</span><span class="p">:</span><span class="s2">&quot;&quot;&quot;You are an assistant who </span><span class="se">\</span>
<span class="s2">responds in the style of Dr Seuss. </span><span class="se">\</span>
<span class="s2">All your responses must be one sentence long.&quot;&quot;&quot;</span><span class="p">},</span>    
<span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span><span class="s1">&#39;user&#39;</span><span class="p">,</span>
 <span class="s1">&#39;content&#39;</span><span class="p">:</span><span class="s2">&quot;&quot;&quot;write me a story about a happy carrot&quot;&quot;&quot;</span><span class="p">},</span>
<span class="p">]</span> 
<span class="n">response</span> <span class="o">=</span> <span class="n">get_completion_from_messages</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> 
                                        <span class="n">temperature</span> <span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Once there was a carrot named Larry, he was jolly and bright orange, never wary.
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">get_completion_and_token_count</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> 
                                   <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">,</span> 
                                   <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
                                   <span class="n">max_tokens</span><span class="o">=</span><span class="mi">500</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    使用 OpenAI 的 GPT-3 模型生成聊天回复，并返回生成的回复内容以及使用的 token 数量。</span>

<span class="sd">    参数:</span>
<span class="sd">    messages: 聊天消息列表。</span>
<span class="sd">    model: 使用的模型名称。默认为&quot;gpt-3.5-turbo&quot;。</span>
<span class="sd">    temperature: 控制生成回复的随机性。值越大，生成的回复越随机。默认为 0。</span>
<span class="sd">    max_tokens: 生成回复的最大 token 数量。默认为 500。</span>

<span class="sd">    返回:</span>
<span class="sd">    content: 生成的回复内容。</span>
<span class="sd">    token_dict: 包含&#39;prompt_tokens&#39;、&#39;completion_tokens&#39;和&#39;total_tokens&#39;的字典，分别表示提示的 token 数量、生成的回复的 token 数量和总的 token 数量。</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
        <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span> 
        <span class="n">max_tokens</span><span class="o">=</span><span class="n">max_tokens</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">content</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="p">[</span><span class="s2">&quot;content&quot;</span><span class="p">]</span>

    <span class="n">token_dict</span> <span class="o">=</span> <span class="p">{</span>
<span class="s1">&#39;prompt_tokens&#39;</span><span class="p">:</span><span class="n">response</span><span class="p">[</span><span class="s1">&#39;usage&#39;</span><span class="p">][</span><span class="s1">&#39;prompt_tokens&#39;</span><span class="p">],</span>
<span class="s1">&#39;completion_tokens&#39;</span><span class="p">:</span><span class="n">response</span><span class="p">[</span><span class="s1">&#39;usage&#39;</span><span class="p">][</span><span class="s1">&#39;completion_tokens&#39;</span><span class="p">],</span>
<span class="s1">&#39;total_tokens&#39;</span><span class="p">:</span><span class="n">response</span><span class="p">[</span><span class="s1">&#39;usage&#39;</span><span class="p">][</span><span class="s1">&#39;total_tokens&#39;</span><span class="p">],</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">content</span><span class="p">,</span> <span class="n">token_dict</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
<span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span><span class="s1">&#39;system&#39;</span><span class="p">,</span> 
 <span class="s1">&#39;content&#39;</span><span class="p">:</span><span class="s2">&quot;&quot;&quot;You are an assistant who responds</span><span class="se">\</span>
<span class="s2"> in the style of Dr Seuss.&quot;&quot;&quot;</span><span class="p">},</span>    
<span class="p">{</span><span class="s1">&#39;role&#39;</span><span class="p">:</span><span class="s1">&#39;user&#39;</span><span class="p">,</span>
 <span class="s1">&#39;content&#39;</span><span class="p">:</span><span class="s2">&quot;&quot;&quot;write me a very short poem \ </span>
<span class="s2"> about a happy carrot&quot;&quot;&quot;</span><span class="p">},</span>  
<span class="p">]</span> 
<span class="n">response</span><span class="p">,</span> <span class="n">token_dict</span> <span class="o">=</span> <span class="n">get_completion_and_token_count</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Oh, the happy carrot, so bright and orange,
Grown in the garden, a joyful forage.
With a smile so wide, from top to bottom,
It brings happiness, oh how it blossoms!

In the soil it grew, with love and care,
Nourished by sunshine, fresh air to share.
Its leaves so green, reaching up so high,
A happy carrot, oh my, oh my!

With a crunch and a munch, it&#39;s oh so tasty,
Filled with vitamins, oh so hasty.
A happy carrot, a delight to eat,
Bringing joy and health, oh what a treat!

So let&#39;s celebrate this veggie so grand,
With a happy carrot in each hand.
For in its presence, we surely find,
A taste of happiness, one of a kind!
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">token_dict</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>{&#39;prompt_tokens&#39;: 37, &#39;completion_tokens&#39;: 164, &#39;total_tokens&#39;: 201}
</code></pre></div>

  <hr>
<div class="md-source-file">
  <small>
    
      最后更新:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2023</span>
      
        <br>
        创建日期:
        <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2023</span>
      
    
  </small>
</div>





                
              </article>
            </div>
          
          
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="页脚" >
        
          
          <a href="../11.%E6%80%BB%E7%BB%93%20conclusion/" class="md-footer__link md-footer__link--prev" aria-label="上一页: 第十一章 总结">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                上一页
              </span>
              <div class="md-ellipsis">
                第十一章 总结
              </div>
            </div>
          </a>
        
        
          
          <a href="../3.%20%E8%AF%84%E4%BC%B0%E8%BE%93%E5%85%A5-%E5%88%86%E7%B1%BB%20Classification/" class="md-footer__link md-footer__link--next" aria-label="下一页: 第三章 评估输入——分类">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                下一页
              </span>
              <div class="md-ellipsis">
                第三章 评估输入——分类
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2023 Ean Yang
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/YQisme" target="_blank" rel="noopener" title="github主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://space.bilibili.com/244185393?spm_id_from=333.788.0.0" target="_blank" rel="noopener" title="b站主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M488.6 104.1c16.7 18.1 24.4 39.7 23.3 65.7v202.4c-.4 26.4-9.2 48.1-26.5 65.1-17.2 17-39.1 25.9-65.5 26.7H92.02c-26.45-.8-48.21-9.8-65.28-27.2C9.682 419.4.767 396.5 0 368.2V169.8c.767-26 9.682-47.6 26.74-65.7C43.81 87.75 65.57 78.77 92.02 78h29.38L96.05 52.19c-5.75-5.73-8.63-13-8.63-21.79 0-8.8 2.88-16.06 8.63-21.797C101.8 2.868 109.1 0 117.9 0s16.1 2.868 21.9 8.603L213.1 78h88l74.5-69.397C381.7 2.868 389.2 0 398 0c8.8 0 16.1 2.868 21.9 8.603 5.7 5.737 8.6 12.997 8.6 21.797 0 8.79-2.9 16.06-8.6 21.79L394.6 78h29.3c26.4.77 48 9.75 64.7 26.1zm-38.8 69.7c-.4-9.6-3.7-17.4-10.7-23.5-5.2-6.1-14-9.4-22.7-9.8H96.05c-9.59.4-17.45 3.7-23.58 9.8-6.14 6.1-9.4 13.9-9.78 23.5v194.4c0 9.2 3.26 17 9.78 23.5s14.38 9.8 23.58 9.8H416.4c9.2 0 17-3.3 23.3-9.8 6.3-6.5 9.7-14.3 10.1-23.5V173.8zm-264.3 42.7c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.2 6.3-14 9.5-23.6 9.5-9.6 0-17.5-3.2-23.6-9.5-6.1-6.3-9.4-14-9.8-23.2v-33.3c.4-9.1 3.8-16.9 10.1-23.2 6.3-6.3 13.2-9.6 23.3-10 9.2.4 17 3.7 23.3 10zm191.5 0c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.1 6.3-14 9.5-23.6 9.5-9.6 0-17.4-3.2-23.6-9.5-7-6.3-9.4-14-9.7-23.2v-33.3c.3-9.1 3.7-16.9 10-23.2 6.3-6.3 14.1-9.6 23.3-10 9.2.4 17 3.7 23.3 10z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://eanyang7.com" target="_blank" rel="noopener" title="个人主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M112 48a48 48 0 1 1 96 0 48 48 0 1 1-96 0zm40 304v128c0 17.7-14.3 32-32 32s-32-14.3-32-32V256.9l-28.6 47.6c-9.1 15.1-28.8 20-43.9 10.9s-20-28.8-10.9-43.9l58.3-97c17.4-28.9 48.6-46.6 82.3-46.6h29.7c33.7 0 64.9 17.7 82.3 46.6l58.3 97c9.1 15.1 4.2 34.8-10.9 43.9s-34.8 4.2-43.9-10.9L232 256.9V480c0 17.7-14.3 32-32 32s-32-14.3-32-32V352h-16z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "navigation.instant.progress", "navigation.tracking", "navigation.prune", "navigation.top", "toc.follow", "header.autohide", "navigation.footer", "search.suggest", "search.highlight", "search.share", "content.action.edit", "content.action.view", "content.code.copy"], "search": "../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.6c14ae12.min.js"></script>
      
    
  </body>
</html>